{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "629542b5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-09T09:03:23.697646Z",
     "iopub.status.busy": "2024-01-09T09:03:23.696864Z",
     "iopub.status.idle": "2024-01-09T09:03:48.325055Z",
     "shell.execute_reply": "2024-01-09T09:03:48.324092Z"
    },
    "papermill": {
     "duration": 24.643584,
     "end_time": "2024-01-09T09:03:48.327642",
     "exception": false,
     "start_time": "2024-01-09T09:03:23.684058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rawpy\r\n",
      "  Obtaining dependency information for rawpy from https://files.pythonhosted.org/packages/35/58/62caf571fba343c93924e3d301210630df49b4751f77491a9da54ebdf0c9/rawpy-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading rawpy-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rawpy) (1.24.3)\r\n",
      "Downloading rawpy-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: rawpy\r\n",
      "Successfully installed rawpy-0.19.0\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.8.1.78)\r\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.24.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install rawpy\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a23c851a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T09:03:48.353926Z",
     "iopub.status.busy": "2024-01-09T09:03:48.353588Z",
     "iopub.status.idle": "2024-01-09T09:03:52.526697Z",
     "shell.execute_reply": "2024-01-09T09:03:52.525924Z"
    },
    "papermill": {
     "duration": 4.189326,
     "end_time": "2024-01-09T09:03:52.529294",
     "exception": false,
     "start_time": "2024-01-09T09:03:48.339968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.parallel import DataParallel\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.init\n",
    "from torchvision.transforms import functional as TF\n",
    "import torchvision.transforms as transforms\n",
    "from torch.distributions import uniform\n",
    "\n",
    "\n",
    "from rawpy import imread\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "from torchvision.transforms import Compose\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca431b6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T09:03:52.554430Z",
     "iopub.status.busy": "2024-01-09T09:03:52.554004Z",
     "iopub.status.idle": "2024-01-09T09:03:52.563834Z",
     "shell.execute_reply": "2024-01-09T09:03:52.562987Z"
    },
    "papermill": {
     "duration": 0.024469,
     "end_time": "2024-01-09T09:03:52.565747",
     "exception": false,
     "start_time": "2024-01-09T09:03:52.541278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_path, transform=None):\n",
    "        self.file_path = file_path\n",
    "        self.transform = transform\n",
    "        self.data = self.read_file()\n",
    "\n",
    "    def read_file(self):\n",
    "        with open(self.file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        data = []\n",
    "        for line in lines:\n",
    "            input_path, target_path, _, _ = line.split()\n",
    "            input_path = input_path.replace('.', '/kaggle/input/sony-train-numpy', 1)\n",
    "            target_path = target_path.replace('.', '/kaggle/input/sony-train-numpy', 1)\n",
    "            data.append((input_path, target_path))\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        time_getItem = time.time()\n",
    "        \n",
    "        input_path, target_path = self.data[index]\n",
    "\n",
    "        # Carica le immagini\n",
    "        input_image_raw = imread(input_path)\n",
    "        target_image_raw = imread(target_path)\n",
    "        \n",
    "        print(f'path: {input_path}')\n",
    "        \n",
    "        time_readRaw = time.time()\n",
    "\n",
    "        # Applica trasformazioni se definite\n",
    "        if self.transform:\n",
    "            input_image, target_image = self.transform(input_image_raw, target_image_raw)\n",
    "            input_image = input_image * 250\n",
    "        else:\n",
    "            input_image, target_image = input_image_raw, target_image_raw\n",
    "            input_image = input_image * 250\n",
    "            \n",
    "        print(f\"Total time: {time.time() - time_getItem}\")\n",
    "\n",
    "        return input_image, target_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "070e9277",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T09:03:52.590297Z",
     "iopub.status.busy": "2024-01-09T09:03:52.589989Z",
     "iopub.status.idle": "2024-01-09T09:03:52.604772Z",
     "shell.execute_reply": "2024-01-09T09:03:52.603935Z"
    },
    "papermill": {
     "duration": 0.029105,
     "end_time": "2024-01-09T09:03:52.606594",
     "exception": false,
     "start_time": "2024-01-09T09:03:52.577489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NumpyDataset(Dataset):\n",
    "    def __init__(self, file_path, transform=None, ops=0):\n",
    "        self.file_path = file_path\n",
    "        self.transform = transform\n",
    "        self.ops = ops\n",
    "        self.data = self.read_file()\n",
    "\n",
    "        \n",
    "    def read_file(self):\n",
    "        with open(self.file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        data = []\n",
    "        for line in lines:\n",
    "            input_path, target_path, _, _ = line.split()\n",
    "\n",
    "            if self.ops == 0:\n",
    "                prefix = '/kaggle/input/sony-train-numpy'\n",
    "            elif self.ops == 1:\n",
    "                prefix = '/kaggle/input/sony-valid-numpy'\n",
    "            else:\n",
    "                prefix = '/kaggle/input/sony-test-numpy'\n",
    "\n",
    "            input_path = input_path.replace('.', prefix, 1)\n",
    "            target_path = target_path.replace('.', prefix, 1)\n",
    "\n",
    "            data.append((input_path, target_path))\n",
    "\n",
    "        return data\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def transform(self, image, gt):\n",
    "        \n",
    "        # Transform to tensor\n",
    "        image = TF.to_tensor(image)\n",
    "        gt = TF.to_tensor(gt)\n",
    "        return image, gt\n",
    "    \n",
    "    \n",
    "    def ratio_eval(self, image_path, tg_path):\n",
    "        \n",
    "        try: \n",
    "            if self.ops == 0: \n",
    "                in_exposure = np.float16(image_path[9:-7])\n",
    "                gt_exposure = np.float16(tg_path[9:-7])\n",
    "            else:\n",
    "                in_exposure = np.float16(image_path[9:-5])\n",
    "                gt_exposure = np.float16(tg_path[9:-5])                \n",
    "                \n",
    "            ratio = min(gt_exposure / in_exposure, 300)\n",
    "            \n",
    "        except ValueError as e:\n",
    "            print(f\"Error converting to np.float16: {e}\")\n",
    "        \n",
    "        return ratio\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        input_path, target_path = self.data[index]\n",
    "        \n",
    "        #time_num = time.time()\n",
    "        \n",
    "        # Carica le immagini\n",
    "        input_image = np.load(input_path)\n",
    "        target_image = np.load(target_path)\n",
    "        \n",
    "        #target_image = cv2.cvtColor(target_image, cv2.COLOR_RGB2HSV)\n",
    "        #target_image = (target_image - target_image.min()) / (target_image.max() - target_image.min())\n",
    "                        \n",
    "        # Applica trasformazioni\n",
    "        \n",
    "        input_image = TF.to_tensor(input_image).permute(1, 2, 0)\n",
    "        target_image = TF.to_tensor(target_image)\n",
    "                        \n",
    "        in_path = os.path.basename(input_path)\n",
    "        gt_path = os.path.basename(target_path)\n",
    "        \n",
    "        input_image = input_image * self.ratio_eval(in_path, gt_path)\n",
    "        \n",
    "        #print(f\"Numpy dataset total time: {time.time() - time_num}\")\n",
    "                \n",
    "        return input_image, target_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9514ad",
   "metadata": {
    "papermill": {
     "duration": 0.011342,
     "end_time": "2024-01-09T09:03:52.629612",
     "exception": false,
     "start_time": "2024-01-09T09:03:52.618270",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e107e2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T09:03:52.654169Z",
     "iopub.status.busy": "2024-01-09T09:03:52.653887Z",
     "iopub.status.idle": "2024-01-09T09:03:52.671470Z",
     "shell.execute_reply": "2024-01-09T09:03:52.670655Z"
    },
    "papermill": {
     "duration": 0.032187,
     "end_time": "2024-01-09T09:03:52.673273",
     "exception": false,
     "start_time": "2024-01-09T09:03:52.641086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RandomCrop:\n",
    "    \"\"\"\n",
    "    Custom function for random cropping (input,target): the results will have the shape\n",
    "    [C, ps, ps] for input and [C, ps*2, ps*2] for target\n",
    "    \"\"\"\n",
    "    def __init__(self, patch_size):\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def __call__(self, input_image, target_image):\n",
    "        \n",
    "        time_cropStart = time.time()\n",
    "\n",
    "        h = input_image.shape[1]\n",
    "        w = input_image.shape[2]\n",
    "        #print(f'Dimensioni immagini input: {h}x{w}')\n",
    "        \n",
    "        # Calcola le coordinate superiori sinistre del crop casuale\n",
    "        top = torch.randint(0, h - self.patch_size + 1, (1,)).item()\n",
    "        left = torch.randint(0, w - self.patch_size + 1, (1,)).item()\n",
    "        \n",
    "        # Applica il crop alle immagini\n",
    "        input_image = np.minimum(input_image[:,top:top+self.patch_size,left:left+self.patch_size], 1.0)\n",
    "        target_image = target_image[:,top*2:top*2+self.patch_size*2,left*2:left*2+self.patch_size*2].clamp(0,1)\n",
    "                        \n",
    "        print(f\"Crop time: {time.time() - time_cropStart}\")\n",
    "                \n",
    "        return input_image, target_image\n",
    "        \n",
    "\n",
    "\n",
    "def pack_raw(raw):\n",
    "    \"\"\"\n",
    "    Custom function to transform the raw format into the RGBG one\n",
    "    \"\"\"\n",
    "    \n",
    "    time_packRawStart = time.time()\n",
    "    \n",
    "    im = raw.raw_image_visible.astype(np.float32)\n",
    "    im = np.maximum(im - 512, 0) / (16383 - 512)  # sottrae il livello di nero e normalizza tra 0 e 1\n",
    "\n",
    "    im = np.expand_dims(im, axis=2)\n",
    "    img_shape = im.shape\n",
    "    H = img_shape[0]\n",
    "    W = img_shape[1]\n",
    "\n",
    "    out = np.concatenate((im[0:H:2, 0:W:2, :],\n",
    "                          im[0:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 0:W:2, :]), axis=2) #serve per creare l'immagine a 4 canali\n",
    "    \n",
    "    print(f\"Time pack raw: {time.time() - time_packRawStart}\")\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "class RawTargetToImage(transforms.ToTensor):\n",
    "    \"\"\"\n",
    "    Class that ovverrides transforms.ToTensor to produce a matrix [C, H, W] from a .arw file\n",
    "    \"\"\"\n",
    "    def __call__(self, pic):\n",
    "        if isinstance(pic, rawpy._rawpy.RawPy):\n",
    "            return self.raw_to_tensor(pic)\n",
    "        return super().__call__(pic)\n",
    "\n",
    "    def raw_to_tensor(self, raw):\n",
    "        \n",
    "        time_postprocessStart = time.time()\n",
    "        \n",
    "        raw_array = raw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
    "        raw_array = np.float32(raw_array / 65535.0)\n",
    "        \n",
    "        print(f\"Time postprocess: {time.time() - time_postprocessStart}\")\n",
    "        \n",
    "        time_cc = time.time()\n",
    "        \n",
    "        hsi_image = cv2.cvtColor(raw_array, cv2.COLOR_RGB2HSV)\n",
    "        \n",
    "        print(f\"Time cc: {time.time() - time_cc}\")\n",
    "        \n",
    "        # Conversione array numpy in un tensore PyTorch\n",
    "        tensor = super().__call__(hsi_image)\n",
    "        \n",
    "        print(tensor.shape)\n",
    "        return tensor\n",
    "    \n",
    "\n",
    "    \n",
    "class RawToModel:\n",
    "    \"\"\"\n",
    "    Class that preprocess input and target: from .arw to matrices\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.raw_to_tensor = RawTargetToImage()\n",
    "\n",
    "    def __call__(self, input_image, target_image):\n",
    "        \n",
    "        input_image_new = np.transpose(pack_raw(input_image), (2, 0, 1))\n",
    "        target_image_new = self.raw_to_tensor(target_image)\n",
    "        return input_image_new, target_image_new\n",
    "    \n",
    "    \n",
    "\n",
    "class MultiImageCompose(Compose):\n",
    "    \"\"\"\n",
    "    Estensione di Compose che accetta trasformazioni per più immagini.\n",
    "    \"\"\"\n",
    "    def __call__(self, *args):\n",
    "        \"\"\"\n",
    "        Esegue le trasformazioni su ogni input in parallelo.\n",
    "        \"\"\"\n",
    "        for transform in self.transforms:\n",
    "            args = transform(*args)\n",
    "        return args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e4e191",
   "metadata": {
    "papermill": {
     "duration": 0.011329,
     "end_time": "2024-01-09T09:03:52.696047",
     "exception": false,
     "start_time": "2024-01-09T09:03:52.684718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "681ed7c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T09:03:52.720224Z",
     "iopub.status.busy": "2024-01-09T09:03:52.719926Z",
     "iopub.status.idle": "2024-01-09T09:03:53.335769Z",
     "shell.execute_reply": "2024-01-09T09:03:53.334562Z"
    },
    "papermill": {
     "duration": 0.629819,
     "end_time": "2024-01-09T09:03:53.337399",
     "exception": true,
     "start_time": "2024-01-09T09:03:52.707580",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/sid-sony/Sony_train_list.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m train_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/sid-sony/Sony_train_list.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m val_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/sid-sony/Sony_val_list.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 10\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mCustomDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m CustomDataset(file_path\u001b[38;5;241m=\u001b[39mval_path, transform\u001b[38;5;241m=\u001b[39mval_transform)\n",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m, in \u001b[0;36mCustomDataset.__init__\u001b[0;34m(self, file_path, transform)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path \u001b[38;5;241m=\u001b[39m file_path\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transform\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m, in \u001b[0;36mCustomDataset.read_file\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_file\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      9\u001b[0m         lines \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m     11\u001b[0m     data \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/sid-sony/Sony_train_list.txt'"
     ]
    }
   ],
   "source": [
    "### RAWPY ###\n",
    "\n",
    "patch_size = 512\n",
    "train_transform = MultiImageCompose([RawToModel(), RandomCrop(patch_size)])\n",
    "val_transform = RawToModel()\n",
    "\n",
    "train_path = '/kaggle/input/sid-sony/Sony_train_list.txt'\n",
    "val_path = '/kaggle/input/sid-sony/Sony_val_list.txt'\n",
    "\n",
    "train_dataset = CustomDataset(file_path=train_path, transform=train_transform)\n",
    "val_dataset = CustomDataset(file_path=val_path, transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b34225",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Prova tempi di elaborazione pipeline RAWPY\n",
    "\n",
    "image, gt = train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bfdaa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T07:50:28.550635Z",
     "iopub.status.busy": "2024-01-09T07:50:28.550120Z",
     "iopub.status.idle": "2024-01-09T07:50:28.635921Z",
     "shell.execute_reply": "2024-01-09T07:50:28.635050Z",
     "shell.execute_reply.started": "2024-01-09T07:50:28.550601Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### NUMPY ###\n",
    "\n",
    "train_np_path = '/kaggle/input/sony-train-list/Sony_train_newlist.txt'\n",
    "val_np_path = '/kaggle/input/sony-valid-list/Sony_val_newlist.txt'\n",
    "\n",
    "train_dataset = NumpyDataset(file_path=train_np_path, transform=None, ops=0)\n",
    "val_dataset = NumpyDataset(file_path=val_np_path, transform=None, ops=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9bc603",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Prova tempi di elaborazione pipeline NUMPY\n",
    "\n",
    "image, gt = train_dataset.__getitem__(10)\n",
    "\n",
    "display_image(gt, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fa6ae1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c42c21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T07:50:28.637243Z",
     "iopub.status.busy": "2024-01-09T07:50:28.636979Z",
     "iopub.status.idle": "2024-01-09T07:50:28.643376Z",
     "shell.execute_reply": "2024-01-09T07:50:28.642531Z",
     "shell.execute_reply.started": "2024-01-09T07:50:28.637219Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_image(tensor_image, hsi=False):\n",
    "    # Assume che tensor_image sia un tensore PyTorch con dimensioni [batch_index, Channel, h, w]\n",
    "    \n",
    "    print(f\"image shape: {tensor_image.shape}\")\n",
    "    image = tensor_image.squeeze().permute(1, 2, 0).cpu().detach().numpy()\n",
    "    image_to_show = image\n",
    "    \n",
    "    print(f\"UTILITY - image shape: {image_to_show.shape}, image min: {np.min(image_to_show)}, image max: {np.max(image_to_show)}\")\n",
    "    \n",
    "    if hsi is True:\n",
    "        image_to_show = cv2.cvtColor(image*360, cv2.COLOR_HSV2RGB)\n",
    "        \n",
    "    plt.imshow(image_to_show)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6315eccf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Metric: SSIM Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8517257a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T07:51:29.255645Z",
     "iopub.status.busy": "2024-01-09T07:51:29.254941Z",
     "iopub.status.idle": "2024-01-09T07:51:29.272484Z",
     "shell.execute_reply": "2024-01-09T07:51:29.271494Z",
     "shell.execute_reply.started": "2024-01-09T07:51:29.255609Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# REFERENCE: https://github.com/aserdega/ssim-pytorch/blob/master/ssim.py\n",
    "\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()\n",
    "    return window\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average = True):\n",
    "    mu1 = F.conv2d(img1, window, padding = window_size//2, groups = channel)\n",
    "    mu2 = F.conv2d(img2, window, padding = window_size//2, groups = channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01**2\n",
    "    C2 = 0.03**2\n",
    "\n",
    "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "class SSIM(torch.nn.Module):\n",
    "    def __init__(self, window_size = 11, size_average = True):\n",
    "        \"\"\"window_size default is 11, size_average is True\"\"\"\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size, self.channel)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size, channel)\n",
    "\n",
    "            if img1.is_cuda:\n",
    "                window = window.cuda(img1.get_device())\n",
    "            window = window.type_as(img1)\n",
    "\n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "        ssim_value = _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
    "        ssim_loss = 1 - ssim_value  # Loss is 1 - SSIM\n",
    "        \n",
    "        return ssim_loss\n",
    "\n",
    "def ssim(img1, img2, window_size = 11, size_average = True):\n",
    "    (_, channel, _, _) = img1.size()\n",
    "    window = create_window(window_size, channel)\n",
    "\n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "\n",
    "    return _ssim(img1, img2, window, window_size, channel, size_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a597f1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88eb49e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T07:50:28.666538Z",
     "iopub.status.busy": "2024-01-09T07:50:28.666199Z",
     "iopub.status.idle": "2024-01-09T07:50:28.694138Z",
     "shell.execute_reply": "2024-01-09T07:50:28.693430Z",
     "shell.execute_reply.started": "2024-01-09T07:50:28.666485Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv9 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv10 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.upconv6 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.upconv7 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.upconv8 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.upconv9 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv11 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv12 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv13 = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv14 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv15 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv16 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv17 = nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv18 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.conv19 = nn.Conv2d(32, 12, kernel_size=1, stride=1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(2)        \n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.apply(self.initialize_weights)\n",
    "        \n",
    "        \n",
    "    def initialize_weights(self, m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "            # Inizializzazione Xavier per i layer convoluzionali\n",
    "            nn.init.xavier_normal_(m.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "            \n",
    "            # Inizializzazione dei bias a zero\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            # Inizializzazione dei pesi e dei bias per i layer di batch normalization\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \n",
    "        conv1 = self.lrelu(self.conv1(x))\n",
    "        #print('conv1:', conv1.shape)\n",
    "        \n",
    "        conv2 = self.lrelu(self.conv2(conv1))\n",
    "        #print('conv2:', conv2.shape)\n",
    "        \n",
    "        pool1 = torch.nn.functional.max_pool2d(conv2, kernel_size=2, stride=2, padding=0)\n",
    "        #print('pool1:', pool1.shape)\n",
    "        \n",
    "        conv3 = self.lrelu(self.conv3(pool1))\n",
    "        #print('conv3:', conv3.shape)\n",
    "        \n",
    "        conv4 = self.lrelu(self.conv4(conv3))\n",
    "        #print('conv4:', conv4.shape)\n",
    "        \n",
    "        pool2 = torch.nn.functional.max_pool2d(conv4, kernel_size=2, stride=2, padding=0)\n",
    "        #print('pool2:', pool2.shape)\n",
    "\n",
    "        conv5 = self.lrelu(self.conv5(pool2))\n",
    "        #print('conv5:', conv5.shape)\n",
    "\n",
    "        conv6 = self.lrelu(self.conv6(conv5))\n",
    "        #print('conv6:', conv6.shape)\n",
    "        \n",
    "        pool3 = torch.nn.functional.max_pool2d(conv6, kernel_size=2, stride=2, padding=0)\n",
    "        #print('pool3:', pool3.shape)\n",
    "\n",
    "        conv7 = self.lrelu(self.conv7(pool3))\n",
    "        #print('conv7:', conv7.shape)\n",
    "        \n",
    "        conv8 = self.lrelu(self.conv8(conv7))\n",
    "        #print('conv8:', conv8.shape)\n",
    "        \n",
    "        pool4 = torch.nn.functional.max_pool2d(conv8, kernel_size=2, stride=2, padding=0)\n",
    "        #print('pool4:', pool4.shape)\n",
    "\n",
    "        conv9 = self.lrelu(self.conv9(pool4))\n",
    "        #print('conv9:', conv9.shape)\n",
    "        \n",
    "        conv10 = self.lrelu(self.conv10(conv9))\n",
    "        #print('conv10:', conv10.shape)\n",
    "\n",
    "        up6 = self.lrelu(self.upconv6(conv10))\n",
    "        #print(\"up6:\", up6.shape)\n",
    "        \n",
    "        concat6 = torch.cat((up6, conv8), dim=1)\n",
    "        #print(\"concat6:\", concat6.shape)\n",
    "        \n",
    "        conv11 = self.lrelu(self.conv11(concat6))\n",
    "        #print('conv11:', conv11.shape)\n",
    "        \n",
    "        conv12 = self.lrelu(self.conv12(conv11))\n",
    "        #print('conv12:', conv12.shape)\n",
    "\n",
    "        up7 = self.upconv7(conv12)\n",
    "        #print('up7:', up7.shape)\n",
    "        \n",
    "        concat7 = torch.cat((up7, conv6), dim=1)\n",
    "        #print('concat7:', concat7.shape)\n",
    "        \n",
    "        conv13 = self.lrelu(self.conv13(concat7))\n",
    "        #print('conv13:', conv13.shape)\n",
    "        \n",
    "        conv14 = self.lrelu(self.conv14(conv13))\n",
    "        #print('conv14:', conv14.shape)\n",
    "\n",
    "        up8 = self.upconv8(conv14)\n",
    "        #print('up8:', up8.shape)\n",
    "        \n",
    "        concat8 = torch.cat((up8, conv4), dim=1)\n",
    "        #print('concat8:', concat8.shape)\n",
    "        \n",
    "        conv15 = self.lrelu(self.conv15(concat8))\n",
    "        #print('conv15:', conv15.shape)\n",
    "        \n",
    "        conv16 = self.lrelu(self.conv16(conv15))\n",
    "        #print('conv16:', conv16.shape)\n",
    "        \n",
    "        up9 = self.upconv9(conv16)\n",
    "        #print('up9:', up9.shape)\n",
    "        \n",
    "        concat9 = torch.cat((up9, conv2), dim=1)\n",
    "        #print('concat9:', concat9.shape)\n",
    "        \n",
    "        conv17 = self.lrelu(self.conv17(concat9))\n",
    "        #print('conv17:', conv17.shape)\n",
    "        \n",
    "        conv18 = self.lrelu(self.conv18(conv17))\n",
    "        #print('conv18:', conv18.shape)\n",
    "\n",
    "        conv19 = self.conv19(conv18)\n",
    "        #print('conv19:', conv19.shape)\n",
    "        \n",
    "        out = self.pixel_shuffle(conv19)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb318ef",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Model: batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c14cc5c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BatchNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BatchNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(256)\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(256)\n",
    "        self.conv9 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn9 = nn.BatchNorm2d(512)\n",
    "        self.conv10 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn10 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.upconv6 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.bnup6 = nn.BatchNorm2d(256)\n",
    "        self.upconv7 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.bnup7 = nn.BatchNorm2d(256)\n",
    "        self.upconv8 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.bnup8 = nn.BatchNorm2d(128)\n",
    "        self.upconv9 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.bnup9 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv11 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn11 = nn.BatchNorm2d(256)\n",
    "        self.conv12 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn12 = nn.BatchNorm2d(256)\n",
    "        self.conv13 = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn13 = nn.BatchNorm2d(128)\n",
    "        self.conv14 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn14 = nn.BatchNorm2d(128)\n",
    "        self.conv15 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn15 = nn.BatchNorm2d(64)\n",
    "        self.conv16 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn16 = nn.BatchNorm2d(64)\n",
    "        self.conv17 = nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn17 = nn.BatchNorm2d(32)\n",
    "        self.conv18 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn18 = nn.BatchNorm2d(32)\n",
    "        self.conv19 = nn.Conv2d(32, 12, kernel_size=1, stride=1)\n",
    "        self.bn19 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.pixel_shuffle = nn.PixelShuffle(2)        \n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.apply(self.initialize_weights)\n",
    "        \n",
    "        \n",
    "    def initialize_weights(self, m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "            # Inizializzazione Xavier per i layer convoluzionali\n",
    "            nn.init.xavier_normal_(m.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "            \n",
    "            # Inizializzazione dei bias a zero\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            # Inizializzazione dei pesi e dei bias per i layer di batch normalization\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        conv1 = self.lrelu(self.bn1(self.conv1(x)))\n",
    "        #print('conv1:', conv1.shape)\n",
    "        \n",
    "        conv2 = self.lrelu(self.bn2(self.conv2(conv1)))\n",
    "        #print('conv2:', conv2.shape)\n",
    "        \n",
    "        pool1 = torch.nn.functional.max_pool2d(conv2, kernel_size=2, stride=2, padding=0)\n",
    "        #print('pool1:', pool1.shape)\n",
    "        \n",
    "        conv3 = self.lrelu(self.bn3(self.conv3(pool1)))\n",
    "        #print('conv3:', conv3.shape)\n",
    "        \n",
    "        conv4 = self.lrelu(self.bn4(self.conv4(conv3)))\n",
    "        #print('conv4:', conv4.shape)\n",
    "        \n",
    "        pool2 = torch.nn.functional.max_pool2d(conv4, kernel_size=2, stride=2, padding=0)\n",
    "        #print('pool2:', pool2.shape)\n",
    "\n",
    "        conv5 = self.lrelu(self.bn5(self.conv5(pool2)))\n",
    "        #print('conv5:', conv5.shape)\n",
    "\n",
    "        conv6 = self.lrelu(self.bn6(self.conv6(conv5)))\n",
    "        #print('conv6:', conv6.shape)\n",
    "        \n",
    "        pool3 = torch.nn.functional.max_pool2d(conv6, kernel_size=2, stride=2, padding=0)\n",
    "        #print('pool3:', pool3.shape)\n",
    "\n",
    "        conv7 = self.lrelu(self.bn7(self.conv7(pool3)))\n",
    "        #print('conv7:', conv7.shape)\n",
    "        \n",
    "        conv8 = self.lrelu(self.bn8(self.conv8(conv7)))\n",
    "        #print('conv8:', conv8.shape)\n",
    "        \n",
    "        pool4 = torch.nn.functional.max_pool2d(conv8, kernel_size=2, stride=2, padding=0)\n",
    "        #print('pool4:', pool4.shape)\n",
    "\n",
    "        conv9 = self.lrelu(self.bn9(self.conv9(pool4)))\n",
    "        #print('conv9:', conv9.shape)\n",
    "        \n",
    "        conv10 = self.lrelu(self.bn10(self.conv10(conv9)))\n",
    "        #print('conv10:', conv10.shape)\n",
    "\n",
    "        up6 = self.lrelu(self.bnup6(self.upconv6(conv10)))\n",
    "        #print(\"up6:\", up6.shape)\n",
    "        \n",
    "        concat6 = torch.cat((up6, conv8), dim=1)\n",
    "        #print(\"concat6:\", concat6.shape)\n",
    "        \n",
    "        conv11 = self.lrelu(self.bn11(self.conv11(concat6)))\n",
    "        #print('conv11:', conv11.shape)\n",
    "        \n",
    "        conv12 = self.lrelu(self.bn12(self.conv12(conv11)))\n",
    "        #print('conv12:', conv12.shape)\n",
    "\n",
    "        up7 = self.upconv7(self.bnup7(conv12))\n",
    "        #print('up7:', up7.shape)\n",
    "        \n",
    "        concat7 = torch.cat((up7, conv6), dim=1)\n",
    "        #print('concat7:', concat7.shape)\n",
    "        \n",
    "        conv13 = self.lrelu(self.bn13(self.conv13(concat7)))\n",
    "        #print('conv13:', conv13.shape)\n",
    "        \n",
    "        conv14 = self.lrelu(self.bn14(self.conv14(conv13)))\n",
    "        #print('conv14:', conv14.shape)\n",
    "\n",
    "        up8 = self.upconv8(self.bnup8(conv14))\n",
    "        #print('up8:', up8.shape)\n",
    "        \n",
    "        concat8 = torch.cat((up8, conv4), dim=1)\n",
    "        #print('concat8:', concat8.shape)\n",
    "        \n",
    "        conv15 = self.lrelu(self.bn15(self.conv15(concat8)))\n",
    "        #print('conv15:', conv15.shape)\n",
    "        \n",
    "        conv16 = self.lrelu(self.bn16(self.conv16(conv15)))\n",
    "        #print('conv16:', conv16.shape)\n",
    "        \n",
    "        up9 = self.upconv9(self.bnup9(conv16))\n",
    "        #print('up9:', up9.shape)\n",
    "        \n",
    "        concat9 = torch.cat((up9, conv2), dim=1)\n",
    "        #print('concat9:', concat9.shape)\n",
    "        \n",
    "        conv17 = self.lrelu(self.bn17(self.conv17(concat9)))\n",
    "        #print('conv17:', conv17.shape)\n",
    "        \n",
    "        conv18 = self.lrelu(self.bn18(self.conv18(conv17)))\n",
    "        #print('conv18:', conv18.shape)\n",
    "\n",
    "        conv19 = self.conv19(self.bn19(conv18))\n",
    "        #print('conv19:', conv19.shape)\n",
    "        \n",
    "        out = self.pixel_shuffle(conv19)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeeea14",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Funzione di fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93738baa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T17:17:23.354657Z",
     "iopub.status.busy": "2024-01-08T17:17:23.353978Z",
     "iopub.status.idle": "2024-01-08T17:17:23.375749Z",
     "shell.execute_reply": "2024-01-08T17:17:23.374673Z",
     "shell.execute_reply.started": "2024-01-08T17:17:23.354624Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit(epochs, model, train_loader, val_loader, criterion1, criterion2, alpha, optimizer, index, train_dim, val_dim, scheduler):\n",
    "    \n",
    "    model.to(device, non_blocking=True)\n",
    "    \n",
    "    if train_dim == 0:\n",
    "        train_dim = len(train_loader)\n",
    "        \n",
    "    if val_dim == 0:\n",
    "        val_dim = len(val_loader)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = DataParallel(model)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    history = {}\n",
    "    min_loss = np.inf\n",
    "    \n",
    "    fit_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        val_iter_loss = []\n",
    "        t_iter_loss = []\n",
    "\n",
    "        since = time.time()\n",
    "        running_loss = 0\n",
    "\n",
    "        #training\n",
    "\n",
    "        model.train()\n",
    "        for batch_idx, (input_batch, target_batch) in enumerate(tqdm(train_loader)):\n",
    "\n",
    "            input_images = input_batch.to(device, non_blocking=True)\n",
    "            target_images = target_batch.to(device, non_blocking=True)\n",
    "            \n",
    "            output = model(input_images).clamp(0,1)\n",
    "                        \n",
    "            loss = alpha*criterion1(output, target_images) + (1-alpha)*(criterion2(output, target_images)/2)                \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            del output, input_images, target_images\n",
    "            \n",
    "            if batch_idx % 15 == 0 and scheduler is not None:\n",
    "                scheduler.step()  \n",
    "                current_lr = optimizer.param_groups[0]['lr']\n",
    "                print(f'Batch index:{batch_idx}, Learning Rate: {current_lr}')\n",
    "                        \n",
    "            t_iter_loss.append(loss.item())  \n",
    "            \n",
    "            if batch_idx >= train_dim:\n",
    "                break\n",
    "                \n",
    "        if epoch == epochs // 2:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] /= 10.0\n",
    "            print(f'Learning rate reduced to {optimizer.param_groups[0][\"lr\"]} at epoch {epoch+1}')\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (input_batch, target_batch) in enumerate(tqdm(val_loader)):\n",
    "\n",
    "                input_images = input_batch.to(device, non_blocking=True)\n",
    "                target_images = target_batch.to(device, non_blocking=True)\n",
    "                \n",
    "                output = model(input_images).clamp(0,1)\n",
    "                \n",
    "                loss = alpha*criterion1(output, target_images) + (1-alpha)*(criterion2(output, target_images)/2)                \n",
    "                \n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                if batch_idx == val_dim-1:\n",
    "                    output_np = output.detach().cpu().numpy()\n",
    "                    output_np = np.transpose(np.squeeze(output_np), (1, 2, 0))\n",
    "                    plt.imshow(output_np)\n",
    "                    plt.axis('off')\n",
    "                    plt.show()\n",
    "                    del output_np\n",
    "                                \n",
    "                del output, input_images, target_images\n",
    "                \n",
    "                val_iter_loss.append(loss.item())\n",
    "                   \n",
    "                if batch_idx >= val_dim:\n",
    "                    break\n",
    "\n",
    "        epoch_dict = {'train_loss': running_loss/(train_dim), 'val_loss': test_loss/val_dim,\n",
    "                     'train_iter_loss': t_iter_loss, 'val_iter_loss': val_iter_loss}\n",
    "        \n",
    "        history[epoch] = epoch_dict\n",
    "        \n",
    "        \"\"\"\n",
    "        train_losses.append(running_loss/(train_dim+1))\n",
    "        test_losses.append(test_loss/(val_dim+1))\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        if min_loss > (test_loss/val_dim):\n",
    "                print('Loss Decreasing {:.5f} >> {:.5f} '.format(min_loss, (test_loss/5)))\n",
    "                min_loss = (test_loss/5)\n",
    "\n",
    "                print('saving model...')\n",
    "                torch.save(model.state_dict(), 'Unet-SID.pth')\n",
    "        \n",
    "        \n",
    "        print(\"Epoch:{}/{}..\".format(epoch+1, epochs),\n",
    "                  \"Train Loss: {:.5f}..\".format(running_loss/(train_dim)),\n",
    "                  \"Val Loss: {:.5f}..\".format(test_loss/(val_dim)),\n",
    "                  \"Time: {:.5f}s\".format(time.time()-since))\n",
    "                  \n",
    "    #history = {'train_loss' : train_losses, 'val_loss': test_losses, 'alpha' : alpha}\n",
    "    print('Total time: {:.5f} m' .format((time.time()- fit_time)/60))\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ffdd5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T17:23:28.972816Z",
     "iopub.status.busy": "2024-01-08T17:23:28.971886Z",
     "iopub.status.idle": "2024-01-08T17:23:29.248566Z",
     "shell.execute_reply": "2024-01-08T17:23:29.247549Z",
     "shell.execute_reply.started": "2024-01-08T17:23:28.972778Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "model = Network()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "models = []\n",
    "weights_folder_path = \"/kaggle/input/4-epoch\"  \n",
    "\n",
    "weight_files = [file for file in os.listdir(weights_folder_path) if file.endswith('.pth')]\n",
    "\n",
    "for weight_file in weight_files:\n",
    "    model = Network()\n",
    "    try:\n",
    "        weight_path = os.path.join(weights_folder_path, weight_file)\n",
    "        state_dict = torch.load(weight_path)\n",
    "\n",
    "        # Create a new OrderedDict that does not contain `module.`\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in state_dict.items():\n",
    "            name = k[7:] # remove `module.`\n",
    "            new_state_dict[name] = v\n",
    "\n",
    "        # Load parameters\n",
    "        model.load_state_dict(new_state_dict)\n",
    "        print(f\"Model loaded successfully from {weight_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"INFO: The file at '{weight_file}' does not exist. Loading an empty default model.\")\n",
    "\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ab7c0e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Babysitting: definizione del learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4fcfb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "train_batch_size = 9\n",
    "val_batch_size = 1\n",
    "\n",
    "train_shuffle = True\n",
    "val_shuffle = False\n",
    "\n",
    "train_dim = 13\n",
    "val_dim = 3\n",
    "\n",
    "criterion1 = nn.L1Loss().to(device, non_blocking=True)\n",
    "criterion2 = SSIM(window_size=11, size_average=True).to(device, non_blocking=True)\n",
    "\n",
    "history_tot = []\n",
    "\n",
    "max_count = 50\n",
    "for count in range(max_count):\n",
    "    model = Network()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    lr = 10**np.random.uniform(-5, -3)\n",
    "    alpha = np.random.uniform(0, 1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    print(f\"count: {count}\\tlr: {lr}, alpha: {alpha}\")\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=train_shuffle, num_workers=3, prefetch_factor=3, persistent_workers=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=val_shuffle, num_workers=3, prefetch_factor=3, persistent_workers=True)\n",
    "\n",
    "    history = fit(epochs, model, train_dataloader, val_dataloader, criterion1, criterion2, alpha, optimizer, count, train_dim, val_dim)\n",
    "    history_master = {'lr': lr, 'history': history, 'alpha': alpha}\n",
    "    \n",
    "    history_tot.append(history_master)\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('history_tot.pkl', 'wb') as file:\n",
    "    pickle.dump(history_tot, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c142cd79",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Plot dei risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac66ee6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "valori_per_grafico = 10\n",
    "sottoliste = [history_tot[i:i+valori_per_grafico] for i in range(0, len(history_tot), valori_per_grafico)]\n",
    "\n",
    "for indice, sottolista in enumerate(sottoliste, start=1):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for data_dict in sottolista:\n",
    "        alpha = data_dict['history']['alpha']\n",
    "        lr = data_dict['lr']\n",
    "        val_loss_values = data_dict['history']['val_loss']\n",
    "        \n",
    "        plt.plot(range(1, len(val_loss_values) + 1), val_loss_values, label = f'Lr: {lr:.5f}, a: {alpha:.2f}')\n",
    "\n",
    "    # Impostazioni del grafico\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.title(f'Andamento Validation Loss (Grafico {indice})')\n",
    "    plt.legend()\n",
    "    \n",
    "    file_name = f'grafico_{indice}.jpg'\n",
    "    plt.savefig(file_name)\n",
    "    plt.close() \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8196523a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Plot mappe di attivazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da421b9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name, param in model.state_dict().items():\n",
    "    print(f\"Layer: {name}, Shape: {param.shape}\")\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdfd5f9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Learning Rate Scheduler: Cosine Annealing Warm Restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b17fcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T17:23:40.207903Z",
     "iopub.status.busy": "2024-01-08T17:23:40.207499Z",
     "iopub.status.idle": "2024-01-08T17:23:40.215146Z",
     "shell.execute_reply": "2024-01-08T17:23:40.214088Z",
     "shell.execute_reply.started": "2024-01-08T17:23:40.207873Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "class CustomCosineAnnealingWarmRestarts(CosineAnnealingWarmRestarts):\n",
    "    def __init__(self, optimizer, T_0, T_mult=1, eta_min=0, save_model_callback=None):\n",
    "        self.save_model_callback = save_model_callback\n",
    "        self.counter = 0\n",
    "        super(CustomCosineAnnealingWarmRestarts, self).__init__(optimizer, T_0, T_mult, eta_min)\n",
    "        \n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        super(CustomCosineAnnealingWarmRestarts, self).step(epoch)\n",
    "\n",
    "        if self.T_cur == 0 and self.save_model_callback is not None:\n",
    "            self.save_model_callback(self.last_epoch, self.counter)\n",
    "            self.counter += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f6fe03",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bd4ede",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_batch_size = 9\n",
    "val_batch_size = 1\n",
    "train_shuffle = True\n",
    "val_shuffle = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Network()\n",
    "criterion1 = nn.L1Loss().to(device, non_blocking=True)\n",
    "criterion2 = SSIM(window_size=11, size_average=True).to(device, non_blocking=True)\n",
    "lr = 0.0002\n",
    "alpha = 0.60\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def save_model(epoch, counter):\n",
    "    print(f\"Saving model state at the end of epoch {epoch}\")\n",
    "    torch.save(model.state_dict(), f'{counter}_SID.pth')\n",
    "\n",
    "scheduler = CustomCosineAnnealingWarmRestarts(optimizer, T_0=222, T_mult=2, eta_min=1e-6, save_model_callback=save_model)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=train_shuffle, num_workers=3, prefetch_factor=3, persistent_workers=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=val_shuffle, num_workers=3, prefetch_factor=3, persistent_workers=True)\n",
    "\n",
    "epochs = 11\n",
    "count = 0  \n",
    "history = fit(epochs, models[0], train_dataloader, val_dataloader, criterion1, criterion2, alpha, optimizer, count, 0, 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8b7511",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T21:18:30.785706Z",
     "iopub.status.busy": "2024-01-08T21:18:30.785273Z",
     "iopub.status.idle": "2024-01-08T21:18:30.913695Z",
     "shell.execute_reply": "2024-01-08T21:18:30.912654Z",
     "shell.execute_reply.started": "2024-01-08T21:18:30.785675Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('dizionario.txt', 'w') as file:\n",
    "    json.dump(history, file, indent=4)\n",
    "    \n",
    "torch.save(model.state_dict(), 'Unet-SID.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821b7f5b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Prediction on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e7f91d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee0ac20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T07:50:53.683019Z",
     "iopub.status.busy": "2024-01-09T07:50:53.682080Z",
     "iopub.status.idle": "2024-01-09T07:50:56.340728Z",
     "shell.execute_reply": "2024-01-09T07:50:56.339777Z",
     "shell.execute_reply.started": "2024-01-09T07:50:53.682976Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_np_path = '/kaggle/input/sony-test-list/Sony_test_newlist.txt'\n",
    "test_dataset = NumpyDataset(file_path=test_np_path, transform=None, ops=2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "test_batch_size = 1\n",
    "test_shuffle = True\n",
    "score_criterion = SSIM(window_size=11, size_average=True).to(device, non_blocking=True)\n",
    "\n",
    "models = []\n",
    "weights_folder_path = \"/kaggle/input/sid-modelensemble/Models\"  \n",
    "\n",
    "weight_files = [file for file in os.listdir(weights_folder_path) if file.endswith('.pth')]\n",
    "\n",
    "for weight_file in weight_files:\n",
    "    model = Network()\n",
    "    try:\n",
    "        weight_path = os.path.join(weights_folder_path, weight_file)\n",
    "        model.load_state_dict(torch.load(weight_path))\n",
    "        print(f\"Model loaded successfully from {weight_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"INFO: The file at '{weight_file}' does not exist. Loading an empty default model.\")\n",
    "\n",
    "    models.append(model)\n",
    "    \n",
    "test_dataloader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=test_shuffle, num_workers=3, prefetch_factor=3, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40bcc77",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Model ensembling test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6022ff",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### SSIM modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6d31dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T07:51:05.216205Z",
     "iopub.status.busy": "2024-01-09T07:51:05.215382Z",
     "iopub.status.idle": "2024-01-09T07:51:05.230671Z",
     "shell.execute_reply": "2024-01-09T07:51:05.229830Z",
     "shell.execute_reply.started": "2024-01-09T07:51:05.216170Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# REFERENCE: https://github.com/aserdega/ssim-pytorch/blob/master/ssim.py\n",
    "\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()\n",
    "    return window\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average = True):\n",
    "    mu1 = F.conv2d(img1, window, padding = window_size//2, groups = channel)\n",
    "    mu2 = F.conv2d(img2, window, padding = window_size//2, groups = channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01**2\n",
    "    C2 = 0.03**2\n",
    "\n",
    "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
    "    return ssim_map\n",
    "    \n",
    "\n",
    "class SSIM_mod(torch.nn.Module):\n",
    "    def __init__(self, window_size = 11, size_average = True):\n",
    "        \"\"\"window_size default is 11, size_average is True\"\"\"\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size, self.channel)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size, channel)\n",
    "\n",
    "            if img1.is_cuda:\n",
    "                window = window.cuda(img1.get_device())\n",
    "            window = window.type_as(img1)\n",
    "\n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "        ssim_map = _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
    "        ssim_loss = 1 - ssim_map.mean()\n",
    "\n",
    "        return ssim_loss, ssim_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542bed79",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Prediction strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b0744",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T07:51:12.480406Z",
     "iopub.status.busy": "2024-01-09T07:51:12.480039Z",
     "iopub.status.idle": "2024-01-09T07:51:12.496427Z",
     "shell.execute_reply": "2024-01-09T07:51:12.495542Z",
     "shell.execute_reply.started": "2024-01-09T07:51:12.480375Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections.abc import Iterable\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "AVERAGE = 0\n",
    "TOP_GSCORE = 1\n",
    "LOC_SCORE = 2\n",
    "\n",
    "def calculate_psnr(prediction, target):\n",
    "    mse = torch.mean((prediction - target) ** 2)\n",
    "    max_pixel_value = 1.0  # Assuming the images are normalized to the range [0, 1]\n",
    "    psnr = 20 * torch.log10(max_pixel_value / torch.sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "def average(predictions, score_criterion, target_images):\n",
    "    output = sum(predictions) / len(predictions)\n",
    "    loss = score_criterion(output, target_images) / 2\n",
    "    return output, loss\n",
    "\n",
    "def top_gscore(predictions, score_criterion, losses):\n",
    "    min_loss_index = min(range(len(losses)), key=losses.__getitem__)\n",
    "    return predictions[min_loss_index], losses[min_loss_index]\n",
    "\n",
    "def test(models, test_loader, score_criterion, test_dim, show_img, strategy):\n",
    "    models = [models] if not isinstance(models, Iterable) else models\n",
    "\n",
    "    for model in models:\n",
    "        model.to(device, non_blocking=True)\n",
    "        model.eval()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    test_time = time.time()\n",
    "\n",
    "    since = time.time()\n",
    "    running_score = 0\n",
    "    running_psnr = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (input_batch, target_batch) in enumerate(tqdm(test_loader)):\n",
    "\n",
    "            input_images = input_batch.to(device, non_blocking=True)\n",
    "            target_images = target_batch.to(device, non_blocking=True)\n",
    "\n",
    "            predictions = []\n",
    "            losses = []\n",
    "\n",
    "            for model in models:\n",
    "                output = model(input_images)\n",
    "                predictions.append(output)\n",
    "                losses.append(score_criterion(output, target_images) / 2)\n",
    "\n",
    "            if strategy == AVERAGE:\n",
    "                ensemble_output, loss = average(predictions, score_criterion, target_images)\n",
    "\n",
    "            elif strategy == TOP_GSCORE:\n",
    "                ensemble_output, loss = top_gscore(predictions, score_criterion, losses)\n",
    "\n",
    "            running_score += 1 - loss.item()\n",
    "\n",
    "            psnr_value = calculate_psnr(ensemble_output, target_images)\n",
    "            running_psnr += psnr_value.item()\n",
    "\n",
    "            if show_img is True:\n",
    "                ensemble_output_np = ensemble_output.detach().cpu().numpy()\n",
    "                ensemble_output_np = np.transpose(np.squeeze(ensemble_output_np), (1, 2, 0))\n",
    "\n",
    "                target_np = target_images.detach().cpu().numpy()\n",
    "                target_np = np.transpose(np.squeeze(target_np), (1, 2, 0))\n",
    "\n",
    "                plt.figure(figsize=(10, 5))\n",
    "\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.imshow(ensemble_output_np)\n",
    "                plt.axis('off')\n",
    "                plt.title('Ensemble Model Output')\n",
    "\n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.imshow(target_np)\n",
    "                plt.axis('off')\n",
    "                plt.title('Target Image')\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "            del ensemble_output, input_images, target_images\n",
    "\n",
    "            if batch_idx >= test_dim - 1:\n",
    "                break\n",
    "\n",
    "        average_score = running_score / test_dim\n",
    "        average_psnr = running_psnr / test_dim\n",
    "        print(\"Test Score: {:.5f}..\".format(average_score),\n",
    "              \"Test PSNR: {:.5f}..\".format(average_psnr),\n",
    "              \"Time: {:.5f}s\".format(time.time() - since))\n",
    "\n",
    "    print('Total time: {:.5f} m'.format((time.time() - test_time) / 60))\n",
    "    return average_score, average_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c9842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T07:53:16.943395Z",
     "iopub.status.busy": "2024-01-09T07:53:16.943020Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "test_dim = len(test_dataloader)\n",
    "scores = []\n",
    "\n",
    "for model in models:\n",
    "    scores.append(test(model, test_dataloader, score_criterion, test_dim, False, TOP_GSCORE))\n",
    "    \n",
    "with open('scores.txt', 'w') as file:\n",
    "    json.dump(scores, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3961efde",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73911d18",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Print andamento loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b51091c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('/kaggle/input/nosched-trial/no_scheduler.txt', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "train_iter_loss = [loss for epoch in data.values() for loss in epoch['train_iter_loss']]\n",
    "val_iter_loss = [loss for epoch in data.values() for loss in epoch['val_iter_loss']]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "iterations = list(range(len(train_iter_loss)))\n",
    "plt.plot(iterations, train_iter_loss, color='blue', label='Train Loss')\n",
    "plt.xlabel('Iterazione')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "iterations = list(range(len(val_iter_loss)))\n",
    "plt.plot(iterations, val_iter_loss, color='red', label='Val Loss')\n",
    "plt.xlabel('Iterazione')\n",
    "plt.ylabel('Val Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4143423,
     "sourceId": 7171298,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4144903,
     "sourceId": 7173404,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4147892,
     "sourceId": 7177361,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4152624,
     "sourceId": 7183770,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4152975,
     "sourceId": 7184228,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4212179,
     "sourceId": 7266864,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4241878,
     "sourceId": 7310273,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 34.378057,
   "end_time": "2024-01-09T09:03:54.571717",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-09T09:03:20.193660",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
